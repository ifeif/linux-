cd /usr/local/hadoop/etc/hadoop/
vim core-site.xml	#编辑配置文件
<configuration>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>file:/usr/local/hadoop/tmp</value>
		<description>Abase for other temporary directories.</description>
	</property>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://localhost:9000</value>
	</property>
</configuration>

vim hdfs-site.xml	#编辑配置文件
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file:/usr/local/hadoop/tmp/dfs/name</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file:/usr/local/hadoop/tmp/dfs/data</value>
	</property>
</configuration>

cd ../..
./bin/hdfs namenode -format	#格式化hdfs文件系统
./sbin/start-dfs.sh	#启动进程
jps	#查看后台进程
网页访问http://127.0.0.1:50070/
./bin/hdfs dfs -mkdir -p /user/hadoop	#在hdfs根目录上创建用户目录
./bin/hdfs dfs -mkdir input	#在hdfs根目录上创建输入目录
./bin/hdfs dfs -put ./etc/hadoop/*.xml input	#上传本地文件到hdfs根目录的input目录
./bin/hdfs dfs -ls input	#查看hdfs上的文件列表
./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output 'dfs[a-z.]+'
./bin/hdfs dfs -cat output/*	#查看hdfs上的文件输出内容

./bin/hdfs dfs -get output/* output	#将hdfs上的文件下载到本地
./sbin/stop-dfs.sh	#关闭hdfs

yarn配置：
yarn是从MapReduce中分离出来的，负责资源管理与任务调度
yarn运行于MapReduce之上，提供了高可用性、高扩展性
使用模板文件练习
mv ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml	#重命名
gedit ./etc/hadoop/mapred-site.xml
<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
</configuration>

gedit ./etc/hadoop/yarn-site.xml
<configuration>
<!-- Site specific YARN configuration properties -->
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
</configuration>

启动YARN
./sbin/start-dfs.sh
./sbin/start-yarn.sh
./sbin/mr-jobhistory-daemon.sh start historyserver	#开启历史服务器，才能在Web中查看任务运行
网页访问：localhost:8088